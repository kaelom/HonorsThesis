#! /usr/bin/env python3

import csv
import argparse
import Bio.Seq
import Bio.SeqIO
import shmlast.app
import gzip
import subprocess

parser = argparse.ArgumentParser()

parser.add_argument("-o",type=str,required=True,help="Absolute path to orthofuse csv file.")
parser.add_argument("-e",type=float,help="Preferred e value.") #future work
parser.add_argument("-p",type=str,default="uniprot_sprot.fasta.gz",help="Preferred protein database.")
parser.add_argument("-t",type=int,default=1,help="Thread count.") #24 on premise
parser.add_argument("-a",action="store_true",help="In addition to producing output file, tack salvaged TransIDs&sewqs onto ortho$
parser.add_argument("-f",type=str,nargs=argparse.REMAINDER,help="List of fasta files.")
args = parser.parse_args()

#do NOT reset every time
genenameseqdb={} #aggregate
genenameseqdbo={} #orthomerged
qualdict={} #aggregate
ortqualdict={} #orthomerged
seqdict={} #aggregate
ortseqdict={} #orthomerged

def builddbs(fasta,seqdicts): #build contig -> seq dictionary for each assembly.fasta file! header = key; value = seq
    name=fasta+".gz"
    handle=gzip.open(name,"rt")
    for record in Bio.SeqIO.parse(handle,"fasta"):
        seqdicts[record.id]=record.seq
    handle.close()

#reduce redundancy here too like in translatedict!!!!!!!!!!!
def qualcheck(inputf,whichdict): #iterate through CSV and make dict that takes best hit key=transid:tuple(eval, secondary, KBID)$
    csvname=inputf+".blastout"
    if "orthomerged" in csvname:
        csvname="orthomerged.blastout"
    with open(csvname,"r") as myfile:
        for row in myfile:
            contig=row.split("\t")[0] #NEEDS TO BE TransID aka header; is this right? FIX THIS FOR NEW FILE ____ NO LONGER CSV!!!
            #print("contig = {0}".format(contig))
            info=(row.split("\t")[10],row.split("\t")[3],row.split("\t")[1].split("|")[2].split("_")[0]) #eval,alignment length,$
            #print ("info = {0}".format(info))
            if contig not in whichdict: #if gene isn't in there at all yet
                whichdict[contig]=info #add it
            else: #if the gene name IS already in there, compare values
                if info[0] < whichdict[contig][0]:
                    whichdict[contig]=info
                elif info[0] == whichdict[contig]:
                    if info[1] > whichdict[contig][1]:
                        whichdict[contig]=info


def translatedict(qualdicts,dbdict,retrieve): #use contsigdb to build gene name:(header,seq) dictionary; type is u for unfused o$
    for eachcontig in qualdicts:
        kbid=qualdicts[eachcontig][2] #KBID aka "gene name"
        if eachcontig == "NODE_10131_length_1841_cov_230.574_g6605_i2":
            print("FOUND IT: {0}".format(kbid))
        #print("'{0}'".format(eachcontig)) 
        getinfo=(eachcontig,retrieve[eachcontig]) #header, seq    
        if kbid not in dbdict.keys():
            dbdict[kbid]=getinfo

#RUNNING THE SCRIPT

for eachone in args.f:
    if ".gz" in eachone:
        print("Please unzip discreet fasta files in args.f, then run again.")
        quit
if ".gz" in args.o:
    print("Please unzip orthoerged file, then run again.")
    quit

print("ok")

for eachone in args.f:
    name=eachone+".blastout"
    print(name)
    blastxcommand=["blastx","-query",eachone,"-db","uniprot_sprot.fasta","-outfmt","6","-num_threads 24","-out",name,"-max_targe$
    print(blastxcommand)
    com=" ".join(blastxcommand)
    subprocess.run(com,shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) #took out result=
    #print(result.stdout.decode('ascii'))
    #print(result.stderr.decode('ascii'))
    print("{0} blasted!".format(eachone))
    rezip=("gzip",eachone)
    fileprep=" ".join(rezip)
    subprocess.run(fileprep,shell=True)
    #print("{1}/n{2}/n blasted {0}".format(eachone,result.returncode,result.stdout.decode('acsii')))

oblastxcommand=["blastx","-query",args.o,"-db","uniprot_sprot.fasta","-outfmt","6","-num_threads 24","-out","orthomerged.blastou$
ocom=" ".join(oblastxcommand)
subprocess.run(ocom,shell=True,stdout=subprocess.PIPE, stderr=subprocess.PIPE)
ortfileprep=("gzip",args.o)
rezip=" ".join(ortfileprep)
subprocess.run(rezip,shell=True)

for all in args.f:
    builddbs(all,seqdict)

builddbs(args.o,ortseqdict)

#QUALCHECK!!!!!!! !!!!!!!!!!!! !!!!!!!!!!!!! !!!!!!!!
for eachcheck in args.f:
    qualcheck(eachcheck,qualdict) #create qualict (the best hits dictionary for all the unfused files)

qualcheck(args.o,ortqualdict) #create ortqualdict (the best hits directory for all the fused files)

translatedict(qualdict,genenameseqdb,seqdict) #translatedict calls builddbs(each) and then translates it; returns most complete $
translatedict(ortqualdict,genenameseqdbo,ortseqdict) #for orthofused files

with open("blast_recovered.txt","w") as myfile: #write output file of missing elements
    for every in genenameseqdb:
        if every not in genenameseqdbo:
            myfile.write(">{0}\n{1}\n".format(genenameseqdb[every][0],genenameseqdb[every][1]))

if args.a: #append recovered elements to orthofused file
    with gzip.open(args.o,"a") as ortfile:
        for every in genenameseqdb:
            if every not in genenameseqdbo:
                out_string = ">{0}\n{1}\n".format(str(genenameseqdb[every][0]),str(genenameseqdb[every][1]))
                ortfile.write(out_string.encode("utf-8"))

for every in args.f:
    name=every+".gz"
    redo=("gunzip",name)
    unzip=" ".join(redo)
    subprocess.run(redo,shell=True)

ortname=args.o+".gz"
ortredo=("gunzip",ortname)
redoing=" ".join(ortredo)
subprocess.run(redoing,shell=True)
